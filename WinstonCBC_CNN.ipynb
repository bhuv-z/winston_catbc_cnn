{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winston: A Cat Breed Classifier CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "duQORE8AInDG",
    "outputId": "0610574f-14ad-427f-93cb-9172b1123cec"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm, trange\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from PIL import ImageFile\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Images to tensors\n",
    "def get_image_tensor(img_path):\n",
    "  img_path = img_path.replace('\\\\', '/')\n",
    "  img = image.load_img(img_path, target_size=(224, 224))\n",
    "  img_array = image.img_to_array(img)\n",
    "  return np.expand_dims(img_array, axis=0)\n",
    "\n",
    "def images_to_tensor(paths):\n",
    "  tensor_list = [get_image_tensor(img_path) for img_path in tqdm(paths)]\n",
    "  return np.vstack(tensor_list)\n",
    "\n",
    "\n",
    "# For Detecting if image is a cat, UNUSED\n",
    "def predict_labels(img_path):\n",
    "  img = preprocess_input(get_image_tensor(img_path))\n",
    "  return np.argmax(ResNet50_model.predict(img))\n",
    "# 281 293\n",
    "def detect_cat(img_path):\n",
    "  prediction = predict_labels(img_path)\n",
    "  return ((prediction <= 293) & (prediction >= 281))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images\n",
    "Skip if image tensors have been pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "c5FIaYppMVSN",
    "outputId": "55171f03-a7b7-44e3-9fd4-b94cebbcf760"
   },
   "outputs": [],
   "source": [
    "def load(path):\n",
    "  data = load_files(path, shuffle=True)\n",
    "  cat_img_files = np.array(data['filenames'])\n",
    "  cat_targets = np_utils.to_categorical(np.array(data['target']), num_classes=12)\n",
    "  return cat_img_files, cat_targets\n",
    "\n",
    "print(\"Loading Test Set\")\n",
    "test_files, test_targets = load('dataset/Testing_Data')\n",
    "# pickle.dump(test_files, open('dataset/test_files.p', 'wb'))\n",
    "# pickle.dump(test_targets, open('dataset/test_targets.p', 'wb'))\n",
    "\n",
    "print(\"Loading Validation Set\")\n",
    "validation_files, validation_targets = load('dataset/Validation_Data')\n",
    "# pickle.dump(validation_files, open('dataset/validation_files.p', 'wb'))\n",
    "# pickle.dump(validation_targets, open('dataset/validation_targets.p', 'wb'))\n",
    "\n",
    "print(\"Loading Train Set\")\n",
    "train_files, train_targets = load('dataset/Training_Data')\n",
    "# pickle.dump(train_files, open('dataset/train_files.p', 'wb'))\n",
    "# pickle.dump(train_targets, open('dataset/train_targets.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Stats**\n",
    "\n",
    "Skip if image tensors have been pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "RIQJ_Q_BOmqE",
    "outputId": "f25e6649-2cfb-47ef-cc23-4cabf9c9daf7"
   },
   "outputs": [],
   "source": [
    "breeds_list = [os.path.split(path)[-1:][0] for path in sorted(glob(\"dataset/Training_Data/*\"))]\n",
    "print(f\"# breeds: {len(breeds_list)}\")\n",
    "print(f\"# total cat images: {len(np.hstack([train_files, validation_files, test_files]))}\")\n",
    "print(f\"# training imaqes: {len(train_files)}\")\n",
    "print(f\"# test images: {len(test_files)}\")\n",
    "print(f\"# validation images: {len(validation_files)}\")\n",
    "\n",
    "# list of breed labels\n",
    "print(\"Dumping breed labels\")\n",
    "print(breeds_list)\n",
    "pickle.dump(breeds_list, open('dataset/classes_list.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images to Tensors\n",
    "Skip if image tensors have been pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "GU5JKLQhVYbg",
    "outputId": "7d0a24b3-e45f-4b43-b273-4d10ceea7d2c"
   },
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "train_tensors = images_to_tensor(train_files).astype('float32')/255\n",
    "validation_tensors = images_to_tensor(validation_files).astype('float32')/255\n",
    "test_tensors = images_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Tensors (Optional)\n",
    "Skip if image tensors have been pickled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XYbJcR3OmvTR"
   },
   "outputs": [],
   "source": [
    "pickle.dump(train_tensors, open('dataset/train_tensors.p', 'wb'), protocol=4)\n",
    "pickle.dump(validation_tensors, open('dataset/validation_tensors.p', 'wb'), protocol=4)\n",
    "pickle.dump(test_tensors, open('dataset/test_tensors.p', 'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run if tensors were pickled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors = pickle.load(open('dataset/train_tensors.p', 'rb'))\n",
    "validation_tensors = pickle.load(open('dataset/validation_tensors.p', 'rb'))\n",
    "test_tensors = pickle.load(open('dataset/test_tensors.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# Train: {len(train_tensors)}\")\n",
    "print(f\"# Validation: {len(validation_tensors)}\")\n",
    "print(f\"# Test: {len(test_tensors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "tu7lZOlFORmC",
    "outputId": "c6f92c4c-9e4c-4d05-9c2a-a3d32cfb9c10"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Building the model\n",
    "\n",
    "model.add(Conv2D(input_shape=train_tensors.shape[1:], filters=6, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=96, kernel_size=5, strides= 2, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(filters=324, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=756, kernel_size=5, strides= 2, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir saved_models\n",
    "checkpointer = ModelCheckpoint(filepath=f\"dataset/saved_models/weights.12breeds._f_{epochs}.best.hdf5\", verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(\n",
    "          train_tensors, train_targets,\n",
    "          validation_data=(validation_tensors, validation_targets),\n",
    "          epochs=epochs, batch_size=64, callbacks=[checkpointer], verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ OR ]\n",
    "\n",
    "**Load pre-trainded model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(f'dataset/saved_models/weights.12breeds._f_{epochs}.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "q2cCKkb9lgFD",
    "outputId": "ed0d24dc-7a08-4b12-a0e1-8a23bd42543b"
   },
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(np.expand_dims(test_tensors[50], axis=0))\n",
    " \n",
    "def display_activation(activations, col_size, row_size, act_index): \n",
    "    activation = activations[act_index]\n",
    "    activation_index=0\n",
    "    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*5,col_size*3))\n",
    "    for row in range(0,row_size):\n",
    "        for col in range(0,col_size):\n",
    "            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n",
    "            activation_index += 1\n",
    "\n",
    "display_activation(activations, 8, 8, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "LPlEb1X8Y2yL",
    "outputId": "7ed05c3f-f14d-4034-b36a-84422f0edcfc"
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_tensors[50][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3IAZXcF5KFEI",
    "outputId": "4e65dade-ab9c-4cbe-917b-c847b5d37c9d"
   },
   "outputs": [],
   "source": [
    "# Pydot library required\n",
    "# !pip install pydot\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats\n",
    "* Must be trained to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 610
    },
    "colab_type": "code",
    "id": "Ga17JXlbQ_Nf",
    "outputId": "9b773324-f8d4-4f25-8a03-185dee302835"
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# Mean Absolute Error\n",
    "plt.plot(history.history['loss'], label='MAE (testing data)')\n",
    "plt.plot(history.history['val_loss'], label='MAE (validation data)')\n",
    "plt.title('Mean Absolute Error')\n",
    "plt.ylabel('MAE value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "plt.clf()\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(history.history['accuracy'], label='Acc (testing data)')\n",
    "plt.plot(history.history['val_accuracy'], label='Acc (validation data)')\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Acc value')\n",
    "plt.xlabel('No. epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHipMzYTIQvb"
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "l72jsohxIt_d",
    "outputId": "6e9cf4cf-cdba-4f61-d601-ee8ba4d6590b"
   },
   "outputs": [],
   "source": [
    "cat_preds = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "test_accuracy = 100*np.sum(np.array(cat_preds)==np.argmax(test_targets, axis=1))/len(cat_preds)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = input(\"Enter image path: \")    # base dir is that of the notebook\n",
    "\n",
    "try:\n",
    "    img_tensor = get_image_tensor(img_path)\n",
    "    \n",
    "    breed_labels = pickle.load(open('dataset/classes_list.p', 'rb'))\n",
    "    \n",
    "    prediction = model.predict_classes(img_tensor, verbose=1)\n",
    "    print(f\"It's a(n) {breed_labels[prediction[0]]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load image:\\n{e})"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CatBreedClassifier_2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
